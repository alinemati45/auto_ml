{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "grPhT-nW727I"
      },
      "outputs": [],
      "source": [
        "# !pip install autokeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9DXNEhlG727J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LBNJD2Y727J"
      },
      "source": [
        "## A Simple Example\n",
        "The first step is to prepare your data. Here we use the [IMDB\n",
        "dataset](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification)\n",
        "as an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dchdCOvf727K",
        "outputId": "ddee6af3-1162-4b2c-f9ea-6a454621195a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 4s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n",
            "b'Zero Day leads you to think, even re-think why two'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # this film was just brilliant casting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-DcX2ul727K"
      },
      "source": [
        "The second step is to run the [TextClassifier](/text_classifier).  As a quick\n",
        "demo, we set epochs to 2.  You can also leave the epochs unspecified for an\n",
        "adaptive number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RcP5S-eQ727K",
        "outputId": "659f4a07-ca69-4d9a-9e07-95db116a09ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 31s]\n",
            "val_loss: 0.2777606248855591\n",
            "\n",
            "Best val_loss So Far: 0.2777606248855591\n",
            "Total elapsed time: 00h 00m 31s\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.4440 - accuracy: 0.7688\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.2429 - accuracy: 0.9031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step\n",
            "782/782 [==============================] - 4s 5ms/step\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.2616 - accuracy: 0.8960\n",
            "[0.26164960861206055, 0.8960000276565552]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the text classifier.\n",
        "clf = ak.TextClassifier(\n",
        "    overwrite=True, max_trials=1\n",
        ")  # It only tries 1 model as a quick demo.\n",
        "# Feed the text classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH0H41YD727K"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data.  As\n",
        "shown in the example below, you can use `validation_split` to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hyfb0TOP727K"
      },
      "outputs": [],
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMgo1Pv727L"
      },
      "source": [
        "You can also use your own validation set instead of splitting it from the\n",
        "training data with `validation_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qhvpGKd727L"
      },
      "outputs": [],
      "source": [
        "split = 5000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6MO1Kb5727L"
      },
      "source": [
        "## Customized Search Space\n",
        "For advanced users, you may customize your search space by using\n",
        "[AutoModel](/auto_model/#automodel-class) instead of\n",
        "[TextClassifier](/text_classifier). You can configure the\n",
        "[TextBlock](/block/#textblock-class) for some high-level configurations, e.g.,\n",
        "`vectorizer` for the type of text vectorization method to use.  You can use\n",
        "'sequence', which uses [TextToInteSequence](/block/#texttointsequence-class) to\n",
        "convert the words to integers and use [Embedding](/block/#embedding-class) for\n",
        "embedding the integer sequences, or you can use 'ngram', which uses\n",
        "[TextToNgramVector](/block/#texttongramvector-class) to vectorize the\n",
        "sentences.  You can also do not specify these arguments, which would leave the\n",
        "different choices to be tuned automatically.  See the following example for\n",
        "detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9YTFRwng727L",
        "outputId": "e48838c9-a537-41c7-e34c-73691af8fb0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 08s]\n",
            "val_loss: 0.3568093478679657\n",
            "\n",
            "Best val_loss So Far: 0.3568093478679657\n",
            "Total elapsed time: 00h 00m 08s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 2s 7ms/step - loss: 0.5288 - accuracy: 0.7630\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.2717 - accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadd3eb3110>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roXQqAXa727L"
      },
      "source": [
        "The usage of [AutoModel](/auto_model/#automodel-class) is similar to the\n",
        "[functional API](https://www.tensorflow.org/guide/keras/functional) of Keras.\n",
        "Basically, you are building a graph, whose edges are blocks and the nodes are\n",
        "intermediate outputs of blocks.  To add an edge from `input_node` to\n",
        "`output_node` with `output_node = ak.[some_block]([block_args])(input_node)`.\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space\n",
        "even further. See the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1P5S2rJW727L",
        "outputId": "d8ef24e1-7629-4d0a-e69d-984e443fda28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 05s]\n",
            "val_loss: 0.6931491494178772\n",
            "\n",
            "Best val_loss So Far: 0.6931491494178772\n",
            "Total elapsed time: 00h 00m 05s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 2s 9ms/step - loss: 0.6932 - accuracy: 0.4864\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6932 - accuracy: 0.4960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadcfa6f650>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextToIntSequence()(input_node)\n",
        "output_node = ak.Embedding()(output_node)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node = ak.ConvBlock(separable=True)(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QzT0oOq727L"
      },
      "source": [
        "## Data Format\n",
        "The AutoKeras TextClassifier is quite flexible for the data format.\n",
        "\n",
        "For the text, the input data should be one-dimensional For the classification\n",
        "labels, AutoKeras accepts both plain labels, i.e. strings or integers, and\n",
        "one-hot encoded encoded labels, i.e. vectors of 0s and 1s.\n",
        "\n",
        "We also support using [tf.data.Dataset](\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable)\n",
        "format for the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FhjMfhdk727M",
        "outputId": "646a41b9-3763-41a5-dcbe-1e9e91c128c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 08s]\n",
            "val_loss: 0.4242302179336548\n",
            "\n",
            "Best val_loss So Far: 0.4242302179336548\n",
            "Total elapsed time: 00h 00m 14s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 4s 13ms/step - loss: 0.6787 - accuracy: 0.5624\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4394 - accuracy: 0.8116\n",
            "782/782 [==============================] - 6s 7ms/step\n",
            "782/782 [==============================] - 5s 7ms/step\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3935 - accuracy: 0.8255\n",
            "[0.393484503030777, 0.8254799842834473]\n"
          ]
        }
      ],
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
        "\n",
        "clf = ak.TextClassifier(overwrite=True, max_trials=2)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}