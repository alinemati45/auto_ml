{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kamg4KtwKgx0",
        "outputId": "5dd10d33-15c6-4c87-9889-9acd57419367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.9.2)\n",
            "Collecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.50.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.20 jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install autokeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xYxW3pNkKgx1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import autokeras as ak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44s6ckIyKgx1"
      },
      "source": [
        "## A Simple Example\n",
        "The first step is to prepare your data. Here we use the [Titanic\n",
        "dataset](https://www.kaggle.com/c/titanic) as an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u43orXsgKgx1",
        "outputId": "b8c396ee-5627-46b7-92ee-1b6062599f0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "30874/30874 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "13049/13049 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxn6DZhlKgx2"
      },
      "source": [
        "The second step is to run the\n",
        "[StructuredDataClassifier](/structured_data_classifier).\n",
        "As a quick demo, we set epochs to 10.\n",
        "You can also leave the epochs unspecified for an adaptive number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TfV5GQ9SKgx2",
        "outputId": "8a66352a-f506-4ba7-a731-f03664d82a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.33043476939201355\n",
            "\n",
            "Best val_accuracy So Far: 0.8608695864677429\n",
            "Total elapsed time: 00h 00m 12s\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.5423\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7512\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7624\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7847\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8166\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8230\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8246\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8325\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8278\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8293\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7917\n",
            "[0.44317367672920227, 0.7916666865348816]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    overwrite=True, max_trials=3\n",
        ")  # It tries 3 different models.\n",
        "# Feed the structured data classifier with training data.\n",
        "clf.fit(\n",
        "    # The path to the train.csv file.\n",
        "    train_file_path,\n",
        "    # The name of the label column.\n",
        "    \"survived\",\n",
        "    epochs=10,\n",
        ")\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_file_path)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_file_path, \"survived\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WgltfJzKgx2"
      },
      "source": [
        "## Data Format\n",
        "The AutoKeras StructuredDataClassifier is quite flexible for the data format.\n",
        "\n",
        "The example above shows how to use the CSV files directly. Besides CSV files,\n",
        "it also supports numpy.ndarray, pandas.DataFrame or [tf.data.Dataset](\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable). The\n",
        "data should be two-dimensional with numerical or categorical values.\n",
        "\n",
        "For the classification labels,\n",
        "AutoKeras accepts both plain labels, i.e. strings or integers, and one-hot encoded\n",
        "encoded labels, i.e. vectors of 0s and 1s.\n",
        "The labels can be numpy.ndarray, pandas.DataFrame, or pandas.Series.\n",
        "\n",
        "The following examples show how the data can be prepared with numpy.ndarray,\n",
        "pandas.DataFrame, and tensorflow.data.Dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hTNKE0kbKgx2",
        "outputId": "4866b99c-703d-4562-d19f-b41d39a94fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.852173924446106\n",
            "\n",
            "Best val_accuracy So Far: 0.8608695864677429\n",
            "Total elapsed time: 00h 00m 12s\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.7305\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7895\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.8022\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8086\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8134\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8262\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8246\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8309\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8389\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8405\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7992\n",
            "[0.44399338960647583, 0.7992424368858337]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# x_train as pandas.DataFrame, y_train as pandas.Series\n",
        "x_train = pd.read_csv(train_file_path)\n",
        "print(type(x_train))  # pandas.DataFrame\n",
        "y_train = x_train.pop(\"survived\")\n",
        "print(type(y_train))  # pandas.Series\n",
        "\n",
        "# You can also use pandas.DataFrame for y_train.\n",
        "y_train = pd.DataFrame(y_train)\n",
        "print(type(y_train))  # pandas.DataFrame\n",
        "\n",
        "# You can also use numpy.ndarray for x_train and y_train.\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "print(type(x_train))  # numpy.ndarray\n",
        "print(type(y_train))  # numpy.ndarray\n",
        "\n",
        "# Preparing testing data.\n",
        "x_test = pd.read_csv(test_file_path)\n",
        "y_test = x_test.pop(\"survived\")\n",
        "\n",
        "# It tries 10 different models.\n",
        "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n",
        "# Feed the structured data classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg__T2cwKgx2"
      },
      "source": [
        "The following code shows how to convert numpy.ndarray to tf.data.Dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zo3DC0zkKgx3",
        "outputId": "d9301b34-f76f-450c-8f4e-256cb298e219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 07s]\n",
            "val_accuracy: 0.8608695864677429\n",
            "\n",
            "Best val_accuracy So Far: 0.8695651888847351\n",
            "Total elapsed time: 00h 00m 18s\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.7656\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.8054\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8182\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8230\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8262\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8246\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8246\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8278\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8309\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8309\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7841\n",
            "[0.4399438500404358, 0.7840909361839294]\n"
          ]
        }
      ],
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices((x_train.astype(np.unicode), y_train))\n",
        "test_set = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test.to_numpy().astype(np.unicode), y_test)\n",
        ")\n",
        "\n",
        "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=10)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saHEzeFyKgx3"
      },
      "source": [
        "You can also specify the column names and types for the data as follows.  The\n",
        "`column_names` is optional if the training data already have the column names,\n",
        "e.g.  pandas.DataFrame, CSV file.  Any column, whose type is not specified will\n",
        "be inferred from the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GAAhFpjbKgx3"
      },
      "outputs": [],
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    column_names=[\n",
        "        \"sex\",\n",
        "        \"age\",\n",
        "        \"n_siblings_spouses\",\n",
        "        \"parch\",\n",
        "        \"fare\",\n",
        "        \"class\",\n",
        "        \"deck\",\n",
        "        \"embark_town\",\n",
        "        \"alone\",\n",
        "    ],\n",
        "    column_types={\"sex\": \"categorical\", \"fare\": \"numerical\"},\n",
        "    max_trials=10,  # It tries 10 different models.\n",
        "    overwrite=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC93XOspKgx3"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data.  As\n",
        "shown in the example below, you can use `validation_split` to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NZmYHW1kKgx3",
        "outputId": "3a05a88a-2619-4752-ec3a-99fdf149d5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.9036144614219666\n",
            "\n",
            "Best val_accuracy So Far: 0.9036144614219666\n",
            "Total elapsed time: 00h 00m 42s\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 1s 3ms/step - loss: 0.6768 - accuracy: 0.5821\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7480\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7943\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8134\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8246\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8293\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8293\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8357\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8389\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70b973f290>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        "    epochs=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFBQ3al1Kgx3"
      },
      "source": [
        "You can also use your own validation set\n",
        "instead of splitting it from the training data with `validation_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u0XAzq5OKgx3"
      },
      "outputs": [],
      "source": [
        "split = 500\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCM5VZunKgx3"
      },
      "source": [
        "## Customized Search Space\n",
        "For advanced users, you may customize your search space by using\n",
        "[AutoModel](/auto_model/#automodel-class) instead of\n",
        "[StructuredDataClassifier](/structured_data_classifier). You can configure the\n",
        "[StructuredDataBlock](/block/#structureddatablock-class) for some high-level\n",
        "configurations, e.g., `categorical_encoding` for whether to use the\n",
        "[CategoricalToNumerical](/block/#categoricaltonumerical-class). You can also do\n",
        "not specify these arguments, which would leave the different choices to be\n",
        "tuned automatically. See the following example for detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kf8dZ3bnKgx3",
        "outputId": "7b85eaf5-8b31-4a16-8d11-fcb2e7e16ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 03s]\n",
            "val_loss: 0.4507189691066742\n",
            "\n",
            "Best val_loss So Far: 0.4507189691066742\n",
            "Total elapsed time: 00h 00m 10s\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 4.5929 - accuracy: 0.3800\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6032 - accuracy: 0.4260\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2.1961 - accuracy: 0.5280\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.0606 - accuracy: 0.5420\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6043 - accuracy: 0.5700\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6738 - accuracy: 0.5800\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.7717 - accuracy: 0.5740\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.5117 - accuracy: 0.6020\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2009 - accuracy: 0.6500\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.4606 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70b9a84e50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "input_node = ak.StructuredDataInput()\n",
        "output_node = ak.StructuredDataBlock(categorical_encoding=True)(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=3\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zBNLgHdKgx4"
      },
      "source": [
        "The usage of [AutoModel](/auto_model/#automodel-class) is similar to the\n",
        "[functional API](https://www.tensorflow.org/guide/keras/functional) of Keras.\n",
        "Basically, you are building a graph, whose edges are blocks and the nodes are\n",
        "intermediate outputs of blocks.\n",
        "To add an edge from `input_node` to `output_node` with\n",
        "`output_node = ak.[some_block]([block_args])(input_node)`.\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space even\n",
        "further. See the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fx3UOGd6Kgx4",
        "outputId": "ecf199e5-dfdc-4263-d7dc-542f6c2fa507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 02s]\n",
            "val_loss: 0.5725904107093811\n",
            "\n",
            "Best val_loss So Far: 0.5725904107093811\n",
            "Total elapsed time: 00h 00m 02s\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.9809 - accuracy: 0.6460\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "input_node = ak.StructuredDataInput()\n",
        "output_node = ak.CategoricalToNumerical()(input_node)\n",
        "output_node = ak.DenseBlock()(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=1)\n",
        "clf.predict(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWBEJRujKgx4"
      },
      "source": [
        "You can also export the best model found by AutoKeras as a Keras Model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eJrW-yGIKgx4",
        "outputId": "b11fa8d2-ab5f-4381-d99e-b7c89018296c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 9)]               0         \n",
            "                                                                 \n",
            " multi_category_encoding (Mu  (None, 9)                0         \n",
            " ltiCategoryEncoding)                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                320       \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            " classification_head_1 (Acti  (None, 1)                0         \n",
            " vation)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,409\n",
            "Trainable params: 1,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.unicode` is a deprecated alias for `np.compat.unicode`. To silence this warning, use `np.compat.unicode` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `str` for which `np.compat.unicode` is itself an alias. Doing this will not modify any behaviour and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25022265],\n",
              "       [0.96676344],\n",
              "       [0.16473292],\n",
              "       [0.9236901 ],\n",
              "       [0.2136606 ],\n",
              "       [0.63005537],\n",
              "       [0.20628439],\n",
              "       [0.7653687 ],\n",
              "       [0.67428654],\n",
              "       [0.27761105],\n",
              "       [0.5912477 ],\n",
              "       [0.33972102],\n",
              "       [0.67899245],\n",
              "       [0.2664869 ],\n",
              "       [0.29663262],\n",
              "       [0.17810853],\n",
              "       [0.55513674],\n",
              "       [0.87535924],\n",
              "       [0.5843467 ],\n",
              "       [0.19847606],\n",
              "       [0.99694556],\n",
              "       [0.19941983],\n",
              "       [0.17302673],\n",
              "       [0.49533063],\n",
              "       [0.99206495],\n",
              "       [0.20161688],\n",
              "       [0.05492683],\n",
              "       [0.9617455 ],\n",
              "       [0.92790306],\n",
              "       [0.19840583],\n",
              "       [0.5046851 ],\n",
              "       [0.09412075],\n",
              "       [0.5089855 ],\n",
              "       [0.19183867],\n",
              "       [0.666005  ],\n",
              "       [0.17079595],\n",
              "       [0.38025293],\n",
              "       [0.56713474],\n",
              "       [0.637302  ],\n",
              "       [0.77338517],\n",
              "       [0.9763142 ],\n",
              "       [0.664979  ],\n",
              "       [0.92973274],\n",
              "       [0.85237014],\n",
              "       [0.28870764],\n",
              "       [0.19593471],\n",
              "       [0.81294185],\n",
              "       [0.2566515 ],\n",
              "       [0.9687344 ],\n",
              "       [0.9845698 ],\n",
              "       [0.6781302 ],\n",
              "       [0.35335493],\n",
              "       [0.30858892],\n",
              "       [0.24333301],\n",
              "       [0.1938259 ],\n",
              "       [0.15562351],\n",
              "       [0.92405266],\n",
              "       [0.93693393],\n",
              "       [0.34405208],\n",
              "       [0.17302673],\n",
              "       [0.17079595],\n",
              "       [0.6567874 ],\n",
              "       [0.15003513],\n",
              "       [0.26229486],\n",
              "       [0.1488817 ],\n",
              "       [0.20097737],\n",
              "       [0.8984096 ],\n",
              "       [0.7946109 ],\n",
              "       [0.17079595],\n",
              "       [0.9977972 ],\n",
              "       [0.20233367],\n",
              "       [0.9603694 ],\n",
              "       [0.09523772],\n",
              "       [0.17079595],\n",
              "       [0.15110755],\n",
              "       [0.9388625 ],\n",
              "       [0.4252671 ],\n",
              "       [0.58639413],\n",
              "       [0.15399413],\n",
              "       [0.17302673],\n",
              "       [0.95156264],\n",
              "       [0.13667245],\n",
              "       [0.13091065],\n",
              "       [0.17302673],\n",
              "       [0.17479043],\n",
              "       [0.64298654],\n",
              "       [0.9103278 ],\n",
              "       [0.6033821 ],\n",
              "       [0.22931318],\n",
              "       [0.5380065 ],\n",
              "       [0.24822986],\n",
              "       [0.08779673],\n",
              "       [0.5380201 ],\n",
              "       [0.9980915 ],\n",
              "       [0.17079593],\n",
              "       [0.76358265],\n",
              "       [0.2242937 ],\n",
              "       [0.22393602],\n",
              "       [0.20978151],\n",
              "       [0.12635343],\n",
              "       [0.2551263 ],\n",
              "       [0.0466532 ],\n",
              "       [0.49199426],\n",
              "       [0.7666394 ],\n",
              "       [0.93803185],\n",
              "       [0.41161183],\n",
              "       [0.9500706 ],\n",
              "       [0.298067  ],\n",
              "       [0.1990114 ],\n",
              "       [0.33001146],\n",
              "       [0.47570017],\n",
              "       [0.72829396],\n",
              "       [0.06409422],\n",
              "       [0.0857243 ],\n",
              "       [0.10288842],\n",
              "       [0.18167399],\n",
              "       [0.95216084],\n",
              "       [0.3238718 ],\n",
              "       [0.16216004],\n",
              "       [0.9465777 ],\n",
              "       [0.07635571],\n",
              "       [0.18674108],\n",
              "       [0.37570298],\n",
              "       [0.7238061 ],\n",
              "       [0.93254596],\n",
              "       [0.9273287 ],\n",
              "       [0.70785964],\n",
              "       [0.33035278],\n",
              "       [0.70211715],\n",
              "       [0.2681934 ],\n",
              "       [0.21943747],\n",
              "       [0.3546697 ],\n",
              "       [0.93565655],\n",
              "       [0.38518733],\n",
              "       [0.7545923 ],\n",
              "       [0.6237452 ],\n",
              "       [0.30997077],\n",
              "       [0.34208632],\n",
              "       [0.13349067],\n",
              "       [0.13701294],\n",
              "       [0.24524221],\n",
              "       [0.73554957],\n",
              "       [0.36104754],\n",
              "       [0.9970786 ],\n",
              "       [0.22393602],\n",
              "       [0.20161688],\n",
              "       [0.3068638 ],\n",
              "       [0.15927804],\n",
              "       [0.9465777 ],\n",
              "       [0.1683071 ],\n",
              "       [0.57925475],\n",
              "       [0.27558   ],\n",
              "       [0.5044403 ],\n",
              "       [0.32431078],\n",
              "       [0.64590454],\n",
              "       [0.32775444],\n",
              "       [0.22666036],\n",
              "       [0.25479135],\n",
              "       [0.9854065 ],\n",
              "       [0.15892906],\n",
              "       [0.44091642],\n",
              "       [0.17059207],\n",
              "       [0.3781747 ],\n",
              "       [0.0923953 ],\n",
              "       [0.2753553 ],\n",
              "       [0.41866907],\n",
              "       [0.24832194],\n",
              "       [0.52183986],\n",
              "       [0.656597  ],\n",
              "       [0.96860194],\n",
              "       [0.16904509],\n",
              "       [0.04297787],\n",
              "       [0.15862846],\n",
              "       [0.36452168],\n",
              "       [0.41866907],\n",
              "       [0.1392788 ],\n",
              "       [0.27263933],\n",
              "       [0.30997077],\n",
              "       [0.22624777],\n",
              "       [0.18917805],\n",
              "       [0.9860119 ],\n",
              "       [0.3703449 ],\n",
              "       [0.18262021],\n",
              "       [0.22203277],\n",
              "       [0.33279467],\n",
              "       [0.19243066],\n",
              "       [0.9409037 ],\n",
              "       [0.99994534],\n",
              "       [0.18463011],\n",
              "       [0.22393602],\n",
              "       [0.6852206 ],\n",
              "       [0.42864683],\n",
              "       [0.20161688],\n",
              "       [0.1335482 ],\n",
              "       [0.85111755],\n",
              "       [0.22206047],\n",
              "       [0.99776405],\n",
              "       [0.9920188 ],\n",
              "       [0.7942747 ],\n",
              "       [0.41425732],\n",
              "       [0.17460246],\n",
              "       [0.65422434],\n",
              "       [0.20161688],\n",
              "       [0.9752668 ],\n",
              "       [0.09808329],\n",
              "       [0.4235165 ],\n",
              "       [0.74225175],\n",
              "       [0.27701744],\n",
              "       [0.1736325 ],\n",
              "       [0.41986883],\n",
              "       [0.74342656],\n",
              "       [0.93983126],\n",
              "       [0.17337345],\n",
              "       [0.20186526],\n",
              "       [0.792426  ],\n",
              "       [0.99975336],\n",
              "       [0.20161688],\n",
              "       [0.44797912],\n",
              "       [0.30189556],\n",
              "       [0.17079595],\n",
              "       [0.9773141 ],\n",
              "       [0.96418256],\n",
              "       [0.63096875],\n",
              "       [0.9352194 ],\n",
              "       [0.9450198 ],\n",
              "       [0.9970989 ],\n",
              "       [0.70382476],\n",
              "       [0.17302673],\n",
              "       [0.39143527],\n",
              "       [0.7324576 ],\n",
              "       [0.99526066],\n",
              "       [0.9941403 ],\n",
              "       [0.22666036],\n",
              "       [0.17887844],\n",
              "       [0.7886149 ],\n",
              "       [0.9465777 ],\n",
              "       [0.9920219 ],\n",
              "       [0.11300138],\n",
              "       [0.35658386],\n",
              "       [0.6074304 ],\n",
              "       [0.9965589 ],\n",
              "       [0.9887107 ],\n",
              "       [0.17302673],\n",
              "       [0.95181084],\n",
              "       [0.10352802],\n",
              "       [0.62775296],\n",
              "       [0.2664869 ],\n",
              "       [0.34799176],\n",
              "       [0.11414348],\n",
              "       [0.4098766 ],\n",
              "       [0.0813053 ],\n",
              "       [0.3016798 ],\n",
              "       [0.38367048],\n",
              "       [0.48474902],\n",
              "       [0.19847627],\n",
              "       [0.1592781 ],\n",
              "       [0.91339463],\n",
              "       [0.08754224],\n",
              "       [0.19941983],\n",
              "       [0.19941983],\n",
              "       [0.4404985 ],\n",
              "       [0.76001006],\n",
              "       [0.0674324 ],\n",
              "       [0.1529337 ],\n",
              "       [0.38025293],\n",
              "       [0.97422504],\n",
              "       [0.17804338],\n",
              "       [0.20161688],\n",
              "       [0.9220919 ],\n",
              "       [0.2886071 ],\n",
              "       [0.30421892],\n",
              "       [0.95377386],\n",
              "       [0.99775845],\n",
              "       [0.29328096],\n",
              "       [0.9991999 ],\n",
              "       [0.15074883],\n",
              "       [0.17302673],\n",
              "       [0.9180527 ],\n",
              "       [0.7364847 ],\n",
              "       [0.22431584],\n",
              "       [0.4519355 ],\n",
              "       [0.990037  ],\n",
              "       [0.24283603],\n",
              "       [0.9790984 ],\n",
              "       [0.470315  ],\n",
              "       [0.22846793],\n",
              "       [0.13937771],\n",
              "       [0.29496068],\n",
              "       [0.3013566 ],\n",
              "       [0.12313098],\n",
              "       [0.1825338 ],\n",
              "       [0.3641194 ],\n",
              "       [0.4291695 ],\n",
              "       [0.6215243 ],\n",
              "       [0.242764  ],\n",
              "       [0.656597  ],\n",
              "       [0.17302673],\n",
              "       [0.24062626],\n",
              "       [0.4235165 ],\n",
              "       [0.10811711],\n",
              "       [0.15196367],\n",
              "       [0.7442788 ],\n",
              "       [0.44950685],\n",
              "       [0.21943747],\n",
              "       [0.19183867],\n",
              "       [0.31171596],\n",
              "       [0.71773964],\n",
              "       [0.75852317],\n",
              "       [0.22393602],\n",
              "       [0.20996867],\n",
              "       [0.73663753],\n",
              "       [0.3016798 ],\n",
              "       [0.33867168],\n",
              "       [0.32195348],\n",
              "       [0.93876135],\n",
              "       [0.9656309 ],\n",
              "       [0.4367735 ],\n",
              "       [0.9999285 ],\n",
              "       [0.16296934],\n",
              "       [0.2821085 ],\n",
              "       [0.3360317 ],\n",
              "       [0.20957825],\n",
              "       [0.16989826],\n",
              "       [0.5773171 ],\n",
              "       [0.6318163 ],\n",
              "       [0.33156717],\n",
              "       [0.5819386 ],\n",
              "       [0.7476813 ],\n",
              "       [0.9890045 ],\n",
              "       [0.18339865],\n",
              "       [0.04252673],\n",
              "       [0.9249435 ],\n",
              "       [0.33282998],\n",
              "       [0.13917427],\n",
              "       [0.69513565],\n",
              "       [0.17079595],\n",
              "       [0.14185351],\n",
              "       [0.10829441],\n",
              "       [0.22439252],\n",
              "       [0.5736889 ],\n",
              "       [0.18262021],\n",
              "       [0.5977549 ],\n",
              "       [0.413211  ],\n",
              "       [0.93733543],\n",
              "       [0.4291695 ],\n",
              "       [0.19373463],\n",
              "       [0.570927  ],\n",
              "       [0.7948008 ],\n",
              "       [0.4235165 ],\n",
              "       [0.04924351],\n",
              "       [0.9692779 ],\n",
              "       [0.6565972 ],\n",
              "       [0.97261125],\n",
              "       [0.21454494],\n",
              "       [0.7039001 ],\n",
              "       [0.48603046],\n",
              "       [0.49763834],\n",
              "       [0.25263542],\n",
              "       [0.9906943 ],\n",
              "       [0.37570298],\n",
              "       [0.26194206],\n",
              "       [0.09632108],\n",
              "       [0.9707457 ],\n",
              "       [0.53135705],\n",
              "       [0.7285138 ],\n",
              "       [0.9197504 ],\n",
              "       [0.92795616],\n",
              "       [0.2041706 ],\n",
              "       [0.5586353 ],\n",
              "       [0.2381048 ],\n",
              "       [0.46209946],\n",
              "       [0.15112916],\n",
              "       [0.96903414],\n",
              "       [0.2288002 ],\n",
              "       [0.9450839 ],\n",
              "       [0.19840583],\n",
              "       [0.15340179],\n",
              "       [0.0708114 ],\n",
              "       [0.9970206 ],\n",
              "       [0.32745692],\n",
              "       [0.592981  ],\n",
              "       [0.34496495],\n",
              "       [0.5367928 ],\n",
              "       [0.1344408 ],\n",
              "       [0.64299965],\n",
              "       [0.36840302],\n",
              "       [0.97535044],\n",
              "       [0.88901645],\n",
              "       [0.96122056],\n",
              "       [0.7116117 ],\n",
              "       [0.7346519 ],\n",
              "       [0.99242   ],\n",
              "       [0.7761298 ],\n",
              "       [0.33382052],\n",
              "       [0.39019728],\n",
              "       [0.96960056],\n",
              "       [0.7246591 ],\n",
              "       [0.22249413],\n",
              "       [0.19879702],\n",
              "       [0.6964987 ],\n",
              "       [0.99715096],\n",
              "       [0.97624564],\n",
              "       [0.18159026],\n",
              "       [0.22393602],\n",
              "       [0.12046341],\n",
              "       [0.17079595],\n",
              "       [0.7373303 ],\n",
              "       [0.29805738],\n",
              "       [0.40713865],\n",
              "       [0.15167238],\n",
              "       [0.0588486 ],\n",
              "       [0.8747779 ],\n",
              "       [0.5716685 ],\n",
              "       [0.3781747 ],\n",
              "       [0.10973388],\n",
              "       [0.77942103],\n",
              "       [0.88202786],\n",
              "       [0.05889817],\n",
              "       [0.98106855],\n",
              "       [0.17079595],\n",
              "       [0.15145475],\n",
              "       [0.97625667],\n",
              "       [0.11589186],\n",
              "       [0.27515647],\n",
              "       [0.5156614 ],\n",
              "       [0.43448707],\n",
              "       [0.79103637],\n",
              "       [0.28974804],\n",
              "       [0.19847606],\n",
              "       [0.94979036],\n",
              "       [0.5711109 ],\n",
              "       [0.17658249],\n",
              "       [0.16177922],\n",
              "       [0.79485244],\n",
              "       [0.85915285],\n",
              "       [0.99592143],\n",
              "       [0.53516495],\n",
              "       [0.18567376],\n",
              "       [0.30997077],\n",
              "       [0.13440874],\n",
              "       [0.90545267],\n",
              "       [0.18552259],\n",
              "       [0.22697218],\n",
              "       [0.5516565 ],\n",
              "       [0.22983532],\n",
              "       [0.06449366],\n",
              "       [0.9410193 ],\n",
              "       [0.18488377],\n",
              "       [0.22424099],\n",
              "       [0.00965325],\n",
              "       [0.11293874],\n",
              "       [0.78236645],\n",
              "       [0.6932072 ],\n",
              "       [0.20957825],\n",
              "       [0.15074883],\n",
              "       [0.7883954 ],\n",
              "       [0.37109315],\n",
              "       [0.27028936],\n",
              "       [0.9273287 ],\n",
              "       [0.5736889 ],\n",
              "       [0.9832044 ],\n",
              "       [0.17811328],\n",
              "       [0.19199355],\n",
              "       [0.17302673],\n",
              "       [0.72821754],\n",
              "       [0.2664674 ],\n",
              "       [0.9386548 ],\n",
              "       [0.17302673],\n",
              "       [0.23754945],\n",
              "       [0.99542886],\n",
              "       [0.3258779 ],\n",
              "       [0.1407218 ],\n",
              "       [0.2856507 ],\n",
              "       [0.34799176],\n",
              "       [0.17479043],\n",
              "       [0.10911405],\n",
              "       [0.794959  ],\n",
              "       [0.93993366],\n",
              "       [0.19826698],\n",
              "       [0.42351663],\n",
              "       [0.3207238 ],\n",
              "       [0.31818327],\n",
              "       [0.99997395],\n",
              "       [0.95380735],\n",
              "       [0.32448328],\n",
              "       [0.8377977 ],\n",
              "       [0.41587964],\n",
              "       [0.3787441 ],\n",
              "       [0.32158482],\n",
              "       [0.9916802 ],\n",
              "       [0.9508331 ],\n",
              "       [0.6132184 ],\n",
              "       [0.9273287 ],\n",
              "       [0.05797874],\n",
              "       [0.20190218],\n",
              "       [0.99221796],\n",
              "       [0.5887115 ],\n",
              "       [0.25005722],\n",
              "       [0.47067204],\n",
              "       [0.9854335 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = clf.export_model()\n",
        "model.summary()\n",
        "print(x_train.dtype)\n",
        "# numpy array in object (mixed type) is not supported.\n",
        "# convert it to unicode.\n",
        "model.predict(x_train.astype(np.unicode))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma6Sb_lyKgx5"
      },
      "source": [
        "## Reference\n",
        "[StructuredDataClassifier](/structured_data_classifier),\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[StructuredDataBlock](/block/#structureddatablock-class),\n",
        "[DenseBlock](/block/#denseblock-class),\n",
        "[StructuredDataInput](/node/#structureddatainput-class),\n",
        "[ClassificationHead](/block/#classificationhead-class),\n",
        "[CategoricalToNumerical](/block/#categoricaltonumerical-class).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "structured_data_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}