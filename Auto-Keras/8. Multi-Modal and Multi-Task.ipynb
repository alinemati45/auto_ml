{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vfo4fN-kc1x8",
        "outputId": "f018daac-30a3-4aec-f47f-313b4328e960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 34.0 MB/s \n",
            "\u001b[?25hCollecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 65.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.9.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.50.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.20 jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install autokeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b38NIgrJc1x9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import autokeras as ak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8x13FRDc1x9"
      },
      "source": [
        "In this tutorial we are making use of the\n",
        "[AutoModel](/auto_model/#automodel-class)\n",
        " API to show how to handle multi-modal data and multi-task.\n",
        "\n",
        "## What is multi-modal?\n",
        "\n",
        "Multi-modal data means each data instance has multiple forms of information.\n",
        "For example, a photo can be saved as a image. Besides the image, it may also\n",
        "have when and where it was taken as its attributes, which can be represented as\n",
        "structured data.\n",
        "\n",
        "## What is multi-task?\n",
        "\n",
        "Multi-task here we refer to we want to predict multiple targets with the same\n",
        "input features. For example, we not only want to classify an image according to\n",
        "its content, but we also want to regress its quality as a float number between\n",
        "0 and 1.\n",
        "\n",
        "The following diagram shows an example of multi-modal and multi-task neural\n",
        "network model.\n",
        "\n",
        "<div class=\"mermaid\">\n",
        "graph TD\n",
        "    id1(ImageInput) --> id3(Some Neural Network Model)\n",
        "    id2(StructuredDataInput) --> id3\n",
        "    id3 --> id4(ClassificationHead)\n",
        "    id3 --> id5(RegressionHead)\n",
        "</div>\n",
        "\n",
        "It has two inputs the images and the structured data. Each image is associated\n",
        "with a set of attributes in the structured data. From these data, we are trying\n",
        "to predict the classification label and the regression value at the same time.\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "To illustrate our idea, we generate some random image and structured data as\n",
        "the multi-modal data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vXo3tCqoc1x-"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_instances = 100\n",
        "# Generate image data.\n",
        "image_data = np.random.rand(num_instances, 32, 32, 3).astype(np.float32)\n",
        "# Generate structured data.\n",
        "structured_data = np.random.rand(num_instances, 20).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBlWW3tmc1x-"
      },
      "source": [
        "We also generate some multi-task targets for classification and regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QH5mynTrc1x-"
      },
      "outputs": [],
      "source": [
        "# Generate regression targets.\n",
        "regression_target = np.random.rand(num_instances, 1).astype(np.float32)\n",
        "# Generate classification labels of five classes.\n",
        "classification_target = np.random.randint(5, size=num_instances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4QDFr3uc1x-"
      },
      "source": [
        "## Build and Train the Model\n",
        "Then we initialize the multi-modal and multi-task model with\n",
        "[AutoModel](/auto_model/#automodel-class).\n",
        "Since this is just a demo, we use small amount of `max_trials` and `epochs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ro-hxoBdc1x_",
        "outputId": "5adce3c1-0122-471c-a8bd-0443aa9bb94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 34s]\n",
            "val_loss: 1.6512309312820435\n",
            "\n",
            "Best val_loss So Far: 1.6512309312820435\n",
            "Total elapsed time: 00h 01m 10s\n",
            "Epoch 1/3\n",
            "4/4 [==============================] - 12s 2s/step - loss: 10.6908 - regression_head_1_loss: 7.4158 - classification_head_1_loss: 3.2750 - regression_head_1_mae: 2.0758 - classification_head_1_accuracy: 0.2300\n",
            "Epoch 2/3\n",
            "4/4 [==============================] - 7s 2s/step - loss: 17.7142 - regression_head_1_loss: 14.3483 - classification_head_1_loss: 3.3659 - regression_head_1_mae: 3.0458 - classification_head_1_accuracy: 0.2000\n",
            "Epoch 3/3\n",
            "4/4 [==============================] - 7s 2s/step - loss: 23.0570 - regression_head_1_loss: 20.0332 - classification_head_1_loss: 3.0239 - regression_head_1_mae: 3.3261 - classification_head_1_accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe652223610>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# Initialize the multi with multiple inputs and outputs.\n",
        "model = ak.AutoModel(\n",
        "    inputs=[ak.ImageInput(), ak.StructuredDataInput()],\n",
        "    outputs=[\n",
        "        ak.RegressionHead(metrics=[\"mae\"]),\n",
        "        ak.ClassificationHead(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]),\n",
        "    ],\n",
        "    overwrite=True,\n",
        "    max_trials=2,\n",
        ")\n",
        "# Fit the model with prepared data.\n",
        "model.fit(\n",
        "    [image_data, structured_data],\n",
        "    [regression_target, classification_target],\n",
        "    epochs=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9cvndsbc1x_"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data.\n",
        "As shown in the example below, you can use `validation_split` to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cUi_IEEgc1x_"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    [image_data, structured_data],\n",
        "    [regression_target, classification_target],\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        "    epochs=2,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k4lkT-Rc1x_"
      },
      "source": [
        "You can also use your own validation set\n",
        "instead of splitting it from the training data with `validation_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4mzEHFtoc1x_"
      },
      "outputs": [],
      "source": [
        "split = 20\n",
        "\n",
        "image_val = image_data[split:]\n",
        "structured_val = structured_data[split:]\n",
        "regression_val = regression_target[split:]\n",
        "classification_val = classification_target[split:]\n",
        "\n",
        "image_data = image_data[:split]\n",
        "structured_data = structured_data[:split]\n",
        "regression_target = regression_target[:split]\n",
        "classification_target = classification_target[:split]\n",
        "\n",
        "model.fit(\n",
        "    [image_data, structured_data],\n",
        "    [regression_target, classification_target],\n",
        "    # Use your own validation set.\n",
        "    validation_data=(\n",
        "        [image_val, structured_val],\n",
        "        [regression_val, classification_val],\n",
        "    ),\n",
        "    epochs=2,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0aIXV26c1x_"
      },
      "source": [
        "## Customized Search Space\n",
        "You can customize your search space.\n",
        "The following figure shows the search space we want to define.\n",
        "\n",
        "<div class=\"mermaid\">\n",
        "graph LR\n",
        "    id1(ImageInput) --> id2(Normalization)\n",
        "    id2 --> id3(Image Augmentation)\n",
        "    id3 --> id4(Convolutional)\n",
        "    id3 --> id5(ResNet V2)\n",
        "    id4 --> id6(Merge)\n",
        "    id5 --> id6\n",
        "    id7(StructuredDataInput) --> id8(CategoricalToNumerical)\n",
        "    id8 --> id9(DenseBlock)\n",
        "    id6 --> id10(Merge)\n",
        "    id9 --> id10\n",
        "    id10 --> id11(Classification Head)\n",
        "    id10 --> id12(Regression Head)\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0P2OjH7Zc1x_",
        "outputId": "a75357e0-267b-400d-c778-a5d7f83af441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 38s]\n",
            "val_loss: 1.8171838521957397\n",
            "\n",
            "Best val_loss So Far: 1.8171838521957397\n",
            "Total elapsed time: 00h 01m 10s\n",
            "Epoch 1/3\n",
            "4/4 [==============================] - 12s 2s/step - loss: 3.3604 - classification_head_1_loss: 1.9266 - regression_head_1_loss: 1.4338 - classification_head_1_accuracy: 0.2000 - regression_head_1_mean_squared_error: 1.4338\n",
            "Epoch 2/3\n",
            "4/4 [==============================] - 7s 2s/step - loss: 5.2418 - classification_head_1_loss: 1.9846 - regression_head_1_loss: 3.2573 - classification_head_1_accuracy: 0.1700 - regression_head_1_mean_squared_error: 3.2573\n",
            "Epoch 3/3\n",
            "4/4 [==============================] - 7s 2s/step - loss: 4.6868 - classification_head_1_loss: 1.8359 - regression_head_1_loss: 2.8509 - classification_head_1_accuracy: 0.3200 - regression_head_1_mean_squared_error: 2.8509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe65075c3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "input_node1 = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node1)\n",
        "output_node = ak.ImageAugmentation()(output_node)\n",
        "output_node1 = ak.ConvBlock()(output_node)\n",
        "output_node2 = ak.ResNetBlock(version=\"v2\")(output_node)\n",
        "output_node1 = ak.Merge()([output_node1, output_node2])\n",
        "\n",
        "input_node2 = ak.StructuredDataInput()\n",
        "output_node = ak.CategoricalToNumerical()(input_node2)\n",
        "output_node2 = ak.DenseBlock()(output_node)\n",
        "\n",
        "output_node = ak.Merge()([output_node1, output_node2])\n",
        "output_node1 = ak.ClassificationHead()(output_node)\n",
        "output_node2 = ak.RegressionHead()(output_node)\n",
        "\n",
        "auto_model = ak.AutoModel(\n",
        "    inputs=[input_node1, input_node2],\n",
        "    outputs=[output_node1, output_node2],\n",
        "    overwrite=True,\n",
        "    max_trials=2,\n",
        ")\n",
        "\n",
        "image_data = np.random.rand(num_instances, 32, 32, 3).astype(np.float32)\n",
        "structured_data = np.random.rand(num_instances, 20).astype(np.float32)\n",
        "regression_target = np.random.rand(num_instances, 1).astype(np.float32)\n",
        "classification_target = np.random.randint(5, size=num_instances)\n",
        "\n",
        "auto_model.fit(\n",
        "    [image_data, structured_data],\n",
        "    [classification_target, regression_target],\n",
        "    batch_size=32,\n",
        "    epochs=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrHBKnqhc1x_"
      },
      "source": [
        "## Data Format\n",
        "You can refer to the documentation of\n",
        "[ImageInput](/node/#imageinput-class),\n",
        "[StructuredDataInput](/node/#structureddatainput-class),\n",
        "[TextInput](/node/#textinput-class),\n",
        "[RegressionHead](/block/#regressionhead-class),\n",
        "[ClassificationHead](/block/#classificationhead-class),\n",
        "for the format of different types of data.\n",
        "You can also refer to the Data Format section of the tutorials of\n",
        "[Image Classification](/tutorial/image_classification/#data-format),\n",
        "[Text Classification](/tutorial/text_classification/#data-format),\n",
        "[Structured Data Classification](\n",
        "/tutorial/structured_data_classification/#data-format).\n",
        "\n",
        "## Reference\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[ImageInput](/node/#imageinput-class),\n",
        "[StructuredDataInput](/node/#structureddatainput-class),\n",
        "[DenseBlock](/block/#denseblock-class),\n",
        "[RegressionHead](/block/#regressionhead-class),\n",
        "[ClassificationHead](/block/#classificationhead-class),\n",
        "[CategoricalToNumerical](/block/#categoricaltonumerical-class).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "multi",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}