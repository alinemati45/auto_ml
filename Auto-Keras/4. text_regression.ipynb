{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rmTJRTxeFrqE",
        "outputId": "a60571d0-b09d-4e9e-efd9-bc05c3c993a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 13.5 MB/s \n",
            "\u001b[?25hCollecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.50.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.27.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 80.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.20 jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install autokeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RiL0WtikFrqF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D11bx2ACFrqF"
      },
      "source": [
        "To make this tutorial easy to follow, we just treat IMDB dataset as a\n",
        "regression dataset. It means we will treat prediction targets of IMDB dataset,\n",
        "which are 0s and 1s as numerical values, so that they can be directly used as\n",
        "the regression targets.\n",
        "\n",
        "## A Simple Example\n",
        "The first step is to prepare your data. Here we use the [IMDB\n",
        "dataset](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification)\n",
        "as an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jpFyKxu_FrqG",
        "outputId": "6a3b1d21-5508-4547-aa7c-44864a1230a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 14s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n",
            "b'Zero Day leads you to think, even re-think why two'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # <START> this film was just brilliant casting <UNK>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2wUAWDFFrqG"
      },
      "source": [
        "The second step is to run the [TextRegressor](/text_regressor).  As a quick\n",
        "demo, we set epochs to 2.  You can also leave the epochs unspecified for an\n",
        "adaptive number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7mhxqBGrFrqG",
        "outputId": "99f7f046-f6c9-41c8-e61f-b7424a04b41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 02m 53s]\n",
            "val_loss: 0.08520140498876572\n",
            "\n",
            "Best val_loss So Far: 0.08520140498876572\n",
            "Total elapsed time: 00h 10m 44s\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 101s 128ms/step - loss: 0.1233 - mean_squared_error: 0.1233\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 101s 129ms/step - loss: 0.0467 - mean_squared_error: 0.0467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 22s 28ms/step\n",
            "782/782 [==============================] - 22s 28ms/step\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 0.1020 - mean_squared_error: 0.1020\n",
            "[0.10200628638267517, 0.10200628638267517]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the text regressor.\n",
        "reg = ak.TextRegressor(overwrite=True, max_trials=10)  # It tries 10 different models.\n",
        "# Feed the text regressor with training data.\n",
        "reg.fit(x_train, y_train, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = reg.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(reg.evaluate(x_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRMe5p2bFrqG"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data.  As\n",
        "shown in the example below, you can use `validation_split` to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RrQVkczaFrqH"
      },
      "outputs": [],
      "source": [
        "reg.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tge7LXjFrqH"
      },
      "source": [
        "You can also use your own validation set instead of splitting it from the\n",
        "training data with `validation_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dcj5t0n1FrqH"
      },
      "outputs": [],
      "source": [
        "split = 5000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "reg.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LASkmAtfFrqH"
      },
      "source": [
        "## Customized Search Space\n",
        "For advanced users, you may customize your search space by using\n",
        "[AutoModel](/auto_model/#automodel-class) instead of\n",
        "[TextRegressor](/text_regressor). You can configure the\n",
        "[TextBlock](/block/#textblock-class) for some high-level configurations, e.g.,\n",
        "`vectorizer` for the type of text vectorization method to use.  You can use\n",
        "'sequence', which uses [TextToInteSequence](/block/#texttointsequence-class) to\n",
        "convert the words to integers and use [Embedding](/block/#embedding-class) for\n",
        "embedding the integer sequences, or you can use 'ngram', which uses\n",
        "[TextToNgramVector](/block/#texttongramvector-class) to vectorize the\n",
        "sentences.  You can also do not specify these arguments, which would leave the\n",
        "different choices to be tuned automatically.  See the following example for\n",
        "detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bgbQ_sh6FrqH",
        "outputId": "6d9fb64e-4b71-47f6-d4ce-f7772560c45b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 06s]\n",
            "val_loss: 0.5288418531417847\n",
            "\n",
            "Best val_loss So Far: 0.5288418531417847\n",
            "Total elapsed time: 00h 00m 06s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6947 - mean_squared_error: 0.6947\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.4138 - mean_squared_error: 0.4138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f06979e9d90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.RegressionHead()(output_node)\n",
        "reg = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "reg.fit(x_train, y_train, epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XVDq9QwFrqH"
      },
      "source": [
        "The usage of [AutoModel](/auto_model/#automodel-class) is similar to the\n",
        "[functional API](https://www.tensorflow.org/guide/keras/functional) of Keras.\n",
        "Basically, you are building a graph, whose edges are blocks and the nodes are\n",
        "intermediate outputs of blocks.  To add an edge from `input_node` to\n",
        "`output_node` with `output_node = ak.[some_block]([block_args])(input_node)`.\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space\n",
        "even further. See the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3rpA1vI0FrqH",
        "outputId": "eca0ea87-a9b8-4aab-c95f-1ce103129e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 18s]\n",
            "val_loss: 0.19695769250392914\n",
            "\n",
            "Best val_loss So Far: 0.19695769250392914\n",
            "Total elapsed time: 00h 00m 18s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 8s 46ms/step - loss: 0.2807 - mean_squared_error: 0.2807\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.2050 - mean_squared_error: 0.2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f069729dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextToIntSequence()(input_node)\n",
        "output_node = ak.Embedding()(output_node)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node = ak.ConvBlock(separable=True)(output_node)\n",
        "output_node = ak.RegressionHead()(output_node)\n",
        "reg = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "reg.fit(x_train, y_train, epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swBHwsvgFrqH"
      },
      "source": [
        "## Data Format\n",
        "The AutoKeras TextRegressor is quite flexible for the data format.\n",
        "\n",
        "For the text, the input data should be one-dimensional For the regression\n",
        "targets, it should be a vector of numerical values.  AutoKeras accepts\n",
        "numpy.ndarray.\n",
        "\n",
        "We also support using [tf.data.Dataset](\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable)\n",
        "format for the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q4ZPqwzLFrqI",
        "outputId": "2405a11c-f598-4f3f-c4d1-1a7888c45e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 10s]\n",
            "val_loss: 0.1789596974849701\n",
            "\n",
            "Best val_loss So Far: 0.17352789640426636\n",
            "Total elapsed time: 00h 00m 22s\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 4s 20ms/step - loss: 0.2456 - mean_squared_error: 0.2456\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 0.1554 - mean_squared_error: 0.1554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step\n",
            "782/782 [==============================] - 5s 6ms/step\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.2016 - mean_squared_error: 0.2016\n",
            "[0.20159365236759186, 0.20159365236759186]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
        "\n",
        "reg = ak.TextRegressor(overwrite=True, max_trials=2)\n",
        "# Feed the tensorflow Dataset to the regressor.\n",
        "reg.fit(train_set, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = reg.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(reg.evaluate(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ei5sPihFrqI"
      },
      "source": [
        "## Reference\n",
        "[TextRegressor](/text_regressor),\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[TextBlock](/block/#textblock-class),\n",
        "[TextToInteSequence](/block/#texttointsequence-class),\n",
        "[Embedding](/block/#embedding-class),\n",
        "[TextToNgramVector](/block/#texttongramvector-class),\n",
        "[ConvBlock](/block/#convblock-class),\n",
        "[TextInput](/node/#textinput-class),\n",
        "[RegressionHead](/block/#regressionhead-class).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}